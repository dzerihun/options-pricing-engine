{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Method Convergence Analysis\n",
    "\n",
    "This notebook analyzes how the binomial tree and Monte Carlo methods converge to the analytical Black-Scholes price.\n",
    "\n",
    "Understanding convergence behavior is crucial for:\n",
    "- **Accuracy**: Knowing how many steps/paths are needed\n",
    "- **Efficiency**: Balancing computation time vs precision\n",
    "- **Reliability**: Ensuring numerical stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.core.option_types import Option, OptionType, ExerciseStyle\n",
    "from src.analysis.convergence import (\n",
    "    binomial_convergence,\n",
    "    monte_carlo_convergence,\n",
    ")\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test option\n",
    "option = Option(\n",
    "    spot=100.0,\n",
    "    strike=100.0,\n",
    "    rate=0.05,\n",
    "    volatility=0.20,\n",
    "    time_to_maturity=1.0,\n",
    "    option_type=OptionType.CALL,\n",
    "    exercise_style=ExerciseStyle.EUROPEAN\n",
    ")\n",
    "\n",
    "print(\"Test Option:\")\n",
    "print(f\"  Type: European {option.option_type.value}\")\n",
    "print(f\"  S={option.spot}, K={option.strike}\")\n",
    "print(f\"  r={option.rate:.0%}, σ={option.volatility:.0%}, T={option.time_to_maturity}yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Binomial Tree Convergence\n",
    "\n",
    "The binomial tree approximates continuous price evolution with discrete up/down movements.\n",
    "\n",
    "### Convergence Rate\n",
    "\n",
    "As the number of steps $n \\to \\infty$, the binomial tree converges to Black-Scholes. The error decreases approximately as $O(1/n)$, meaning:\n",
    "- **Doubling steps** roughly halves the error\n",
    "- **10x more steps** reduces error by ~10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test convergence with various step counts\n",
    "steps_list = [5, 10, 25, 50, 100, 200, 500, 1000]\n",
    "\n",
    "bs_price, bin_prices, bin_errors = binomial_convergence(option, steps_list)\n",
    "\n",
    "print(f\"Black-Scholes Price: ${bs_price:.6f}\")\n",
    "print()\n",
    "print(\"Binomial Tree Convergence:\")\n",
    "print(f\"{'Steps':<8} {'Price':<12} {'Error':<12} {'|Error|'}\")\n",
    "print(\"-\" * 42)\n",
    "for steps, price, error in zip(steps_list, bin_prices, bin_errors):\n",
    "    print(f\"{steps:<8} ${price:<11.6f} {error:+.6f}    {abs(error):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot binomial convergence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Price vs Steps\n",
    "ax1.plot(steps_list, bin_prices, 'bo-', markersize=6, linewidth=1.5, label='Binomial Price')\n",
    "ax1.axhline(y=bs_price, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Black-Scholes (${bs_price:.4f})')\n",
    "ax1.set_xlabel('Number of Steps', fontsize=12)\n",
    "ax1.set_ylabel('Option Price ($)', fontsize=12)\n",
    "ax1.set_title('Binomial Tree Price Convergence', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.set_xscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Absolute Error vs Steps (log-log)\n",
    "abs_errors = [abs(e) for e in bin_errors]\n",
    "ax2.plot(steps_list, abs_errors, 'go-', markersize=6, linewidth=1.5)\n",
    "ax2.set_xlabel('Number of Steps', fontsize=12)\n",
    "ax2.set_ylabel('Absolute Error ($)', fontsize=12)\n",
    "ax2.set_title('Binomial Tree Error Reduction', fontsize=14)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add O(1/n) reference line\n",
    "ref_steps = np.array([10, 1000])\n",
    "ref_error = abs_errors[1] * (steps_list[1] / ref_steps)  # Scale from first point\n",
    "ax2.plot(ref_steps, ref_error, 'r--', alpha=0.5, label=r'$O(1/n)$ reference')\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Convergence Insights\n",
    "\n",
    "1. **Rapid initial convergence**: Going from 5 to 50 steps dramatically reduces error\n",
    "2. **Diminishing returns**: Going from 500 to 1000 steps provides little additional accuracy\n",
    "3. **Oscillation**: Errors can oscillate between positive and negative (odd vs even steps)\n",
    "4. **Practical recommendation**: 100-200 steps is usually sufficient for most applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Monte Carlo Convergence\n",
    "\n",
    "Monte Carlo estimates the option price by averaging simulated payoffs.\n",
    "\n",
    "### Convergence Rate\n",
    "\n",
    "By the Central Limit Theorem, the standard error decreases as $O(1/\\sqrt{n})$:\n",
    "- **4x more paths** halves the standard error\n",
    "- **100x more paths** reduces SE by 10x\n",
    "\n",
    "This is slower than binomial convergence, but Monte Carlo is more flexible for complex payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test convergence with various path counts\n",
    "paths_list = [1000, 5000, 10000, 50000, 100000, 500000]\n",
    "\n",
    "bs_price_mc, mc_prices, mc_std_errors = monte_carlo_convergence(option, paths_list, seed=42)\n",
    "\n",
    "print(f\"Black-Scholes Price: ${bs_price_mc:.6f}\")\n",
    "print()\n",
    "print(\"Monte Carlo Convergence:\")\n",
    "print(f\"{'Paths':<10} {'Price':<12} {'Std Error':<12} {'Error vs BS'}\")\n",
    "print(\"-\" * 48)\n",
    "for paths, price, se in zip(paths_list, mc_prices, mc_std_errors):\n",
    "    error = price - bs_price_mc\n",
    "    print(f\"{paths:<10,} ${price:<11.4f} ±{se:<11.4f} {error:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Monte Carlo convergence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Price vs Paths with error bars\n",
    "ax1.errorbar(paths_list, mc_prices, yerr=mc_std_errors, \n",
    "             fmt='bo-', markersize=6, linewidth=1.5, capsize=4, capthick=1.5,\n",
    "             label='Monte Carlo ± 1 SE')\n",
    "ax1.axhline(y=bs_price_mc, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Black-Scholes (${bs_price_mc:.4f})')\n",
    "ax1.set_xlabel('Number of Paths', fontsize=12)\n",
    "ax1.set_ylabel('Option Price ($)', fontsize=12)\n",
    "ax1.set_title('Monte Carlo Price Convergence', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.set_xscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Standard Error vs Paths (log-log)\n",
    "ax2.plot(paths_list, mc_std_errors, 'go-', markersize=6, linewidth=1.5)\n",
    "ax2.set_xlabel('Number of Paths', fontsize=12)\n",
    "ax2.set_ylabel('Standard Error ($)', fontsize=12)\n",
    "ax2.set_title('Monte Carlo Standard Error Reduction', fontsize=14)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add O(1/sqrt(n)) reference line\n",
    "ref_paths = np.array([1000, 500000])\n",
    "ref_se = mc_std_errors[0] * np.sqrt(paths_list[0] / ref_paths)\n",
    "ax2.plot(ref_paths, ref_se, 'r--', alpha=0.5, label=r'$O(1/\\sqrt{n})$ reference')\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Convergence Insights\n",
    "\n",
    "1. **Slow convergence**: Need 100x more paths to reduce error by 10x\n",
    "2. **Error bars shrink**: Confidence intervals narrow with more paths\n",
    "3. **Random variation**: Unlike binomial, MC prices vary randomly around the true value\n",
    "4. **Practical recommendation**: 100,000 paths typically gives ~0.03 SE for standard options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Binomial vs Monte Carlo\n",
    "\n",
    "| Aspect | Binomial Tree | Monte Carlo |\n",
    "|--------|---------------|-------------|\n",
    "| Convergence rate | $O(1/n)$ | $O(1/\\sqrt{n})$ |\n",
    "| Error type | Deterministic | Stochastic |\n",
    "| American options | Yes | Difficult |\n",
    "| Path-dependent | Limited | Excellent |\n",
    "| High dimensions | Poor | Excellent |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "- **Binomial**: American options, simple European options where speed matters\n",
    "- **Monte Carlo**: Path-dependent options, high-dimensional problems, when you need confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Both numerical methods converge to the Black-Scholes price:\n",
    "\n",
    "1. **Binomial tree**: Fast $O(1/n)$ convergence; 100-200 steps usually sufficient\n",
    "2. **Monte Carlo**: Slower $O(1/\\sqrt{n})$ convergence; 100k paths for ~1% precision\n",
    "\n",
    "The choice depends on the specific application, with binomial preferred for American options and Monte Carlo for complex path-dependent payoffs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
